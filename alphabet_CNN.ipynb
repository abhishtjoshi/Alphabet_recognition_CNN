{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 92,570\n",
      "Trainable params: 92,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (32,32,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 26, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 501 images belonging to 26 classes.\n",
      "Found 260 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = 'Training',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = 'Testing',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9275WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1800 - accuracy: 0.9301 - val_loss: 0.2589 - val_accuracy: 0.9115\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1698 - accuracy: 0.9281\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1564 - accuracy: 0.9202\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1677 - accuracy: 0.9162\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1497 - accuracy: 0.9381\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1649 - accuracy: 0.9321\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1290 - accuracy: 0.9401\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1253 - accuracy: 0.9421\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1896 - accuracy: 0.9142\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1515 - accuracy: 0.9222\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1324 - accuracy: 0.9441\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1196 - accuracy: 0.9401\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1510 - accuracy: 0.9441\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1706 - accuracy: 0.9261\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.1108 - accuracy: 0.9561\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1294 - accuracy: 0.9401\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.1360 - accuracy: 0.9461\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2342 - accuracy: 0.9281\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1107 - accuracy: 0.9521\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1541 - accuracy: 0.9301\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1018 - accuracy: 0.9601\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1035 - accuracy: 0.9601\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1047 - accuracy: 0.9521\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1432 - accuracy: 0.9341\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1012 - accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_generator,\n",
    "                         steps_per_epoch = 16,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_generator,\n",
    "                         validation_steps = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    if result[0][0] == 1:\n",
    "        return('a')\n",
    "    elif result[0][1] == 1:\n",
    "        return ('b')\n",
    "    elif result[0][2] == 1:\n",
    "        return ('c')\n",
    "    elif result[0][3] == 1:\n",
    "        return ('d')\n",
    "    elif result[0][4] == 1:\n",
    "        return ('e')\n",
    "    elif result[0][5] == 1:\n",
    "        return ('f')\n",
    "    elif result[0][6] == 1:\n",
    "        return ('g')\n",
    "    elif result[0][7] == 1:\n",
    "        return ('h')\n",
    "    elif result[0][8] == 1:\n",
    "        return ('i')\n",
    "    elif result[0][9] == 1:\n",
    "        return ('j')\n",
    "    elif result[0][10] == 1:\n",
    "        return ('k')\n",
    "    elif result[0][11] == 1:\n",
    "        return ('l')\n",
    "    elif result[0][12] == 1:\n",
    "        return ('m')\n",
    "    elif result[0][13] == 1:\n",
    "        return ('n')\n",
    "    elif result[0][14] == 1:\n",
    "        return ('o')\n",
    "    elif result[0][15] == 1:\n",
    "        return ('p')\n",
    "    elif result[0][16] == 1:\n",
    "        return ('q')\n",
    "    elif result[0][17] == 1:\n",
    "        return ('r')\n",
    "    elif result[0][18] == 1:\n",
    "        return ('s')\n",
    "    elif result[0][19] == 1:\n",
    "        return ('t')\n",
    "    elif result[0][20] == 1:\n",
    "        return ('u')\n",
    "    elif result[0][21] == 1:\n",
    "        return ('v')\n",
    "    elif result[0][22] == 1:\n",
    "        return ('w')\n",
    "    elif result[0][23] == 1:\n",
    "        return ('x')\n",
    "    elif result[0][24] == 1:\n",
    "        return ('y')\n",
    "    elif result[0][25] == 1:\n",
    "        return ('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# img=mpimg.imread('image_name.png')\n",
    "filename = r'Testing\\j\\21.png'\n",
    "test_image = image.load_img(filename, target_size = (32,32))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Alphabet is: j\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model.predict(test_image)\n",
    "result = get_result(result)\n",
    "print ('Predicted Alphabet is: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
